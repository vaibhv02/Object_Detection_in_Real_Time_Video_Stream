{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load YOLO\n",
    "#net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\") # Original yolov3\n",
    "net = cv2.dnn.readNet(\"yolov3-tiny.weights\",\"yolov3-tiny.cfg\") #Tiny Yolo\n",
    "classes = []\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of all the layers in the YOLO network\n",
    "layer_names = net.getLayerNames()\n",
    "\n",
    "# Get the output layers, which are the layers responsible for making predictions\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolo_16', 'yolo_23']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors= np.random.uniform(0,255,size=(len(classes),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(frame,\u001b[38;5;241m0.00392\u001b[39m,(\u001b[38;5;241m320\u001b[39m,\u001b[38;5;241m320\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),\u001b[38;5;28;01mTrue\u001b[39;00m,crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#reduce 416 to 320    \u001b[39;00m\n\u001b[0;32m     17\u001b[0m net\u001b[38;5;241m.\u001b[39msetInput(blob)\n\u001b[1;32m---> 18\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#print(outs[1])\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#Showing info on screen/ get confidence score of algorithm in detecting an object in blob\u001b[39;00m\n\u001b[0;32m     23\u001b[0m class_ids\u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loading image\n",
    "#cap=cv2.VideoCapture(\"22.mp4\") #0 for 1st webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "starting_time= time.time()\n",
    "frame_id = 0\n",
    "\n",
    "while True:\n",
    "    _,frame= cap.read() # \n",
    "    frame_id+=1\n",
    "    \n",
    "    height,width,channels = frame.shape\n",
    "    #detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(frame,0.00392,(320,320),(0,0,0),True,crop=False) #reduce 416 to 320    \n",
    "\n",
    "        \n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    #print(outs[1])\n",
    "\n",
    "\n",
    "    #Showing info on screen/ get confidence score of algorithm in detecting an object in blob\n",
    "    class_ids=[]\n",
    "    confidences=[]\n",
    "    boxes=[]\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.3:\n",
    "                #onject detected\n",
    "                center_x= int(detection[0]*width)\n",
    "                center_y= int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                #cv2.circle(img,(center_x,center_y),10,(0,255,0),2)\n",
    "                #rectangle co-ordinaters\n",
    "                x=int(center_x - w/2)\n",
    "                y=int(center_y - h/2)\n",
    "                #cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "                boxes.append([x,y,w,h]) #put all rectangle areas\n",
    "                confidences.append(float(confidence)) #how confidence was that object detected and show that percentage\n",
    "                class_ids.append(class_id) #name of the object tha was detected\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.4,0.6)\n",
    "\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence= confidences[i]\n",
    "            color = colors[class_ids[i]]\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),color,2)\n",
    "            cv2.putText(frame,label+\" \"+str(round(confidence,2)),(x,y+30),font,1,(255,255,255),2)\n",
    "            \n",
    "\n",
    "    elapsed_time = time.time() - starting_time\n",
    "    fps=frame_id/elapsed_time\n",
    "    cv2.putText(frame,\"FPS:\"+str(round(fps,2)),(10,50),font,2,(0,0,0),1)\n",
    "    \n",
    "    cv2.imshow(\"Image\",frame)\n",
    "    key = cv2.waitKey(1) #wait 1ms the loop will start again and we will process the next frame\n",
    "    \n",
    "    if key == 27: #esc key stops the process\n",
    "        break;\n",
    "    \n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
